{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[nltk_data] Downloading package stopwords to\n[nltk_data]     C:\\Users\\jackm\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package wordnet to\n[nltk_data]     C:\\Users\\jackm\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import typing\n",
    "import matplotlib.pyplot as plt\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "       Unnamed: 0                                     SearchKeywords  \\\n14039       14039  racism OR COVID-19 OR COVID2019 OR Lombardy OR...   \n25327       25327  racism OR COVID-19 OR COVID2019 OR Lombardy OR...   \n38933       38933  racism OR COVID-19 OR COVID2019 OR Lombardy OR...   \n32293       32293  racism OR COVID-19 OR COVID2019 OR Lombardy OR...   \n3053         3053  racism OR COVID-19 OR COVID2019 OR Lombardy OR...   \n\n      SearchCity  Time_Zone      tweet_ID          created_at  \\\n14039    Palermo        1.0  1.239500e+18 2020-03-16 10:31:28   \n25327    Palermo        1.0  1.242368e+18 2020-03-24 08:31:06   \n38933    Palermo        1.0  1.247923e+18 2020-04-08 16:22:29   \n32293    Palermo        1.0  1.244940e+18 2020-03-31 10:48:11   \n3053     Palermo        1.0  1.236779e+18 2020-03-08 22:21:58   \n\n         created_at_local                                          full_text  \\\n14039 2020-03-16 11:31:28  RT @GDS_it: #Coronavirus, #Diodato in tv dedic...   \n25327 2020-03-24 09:31:06  RT @e_terranova: In #Spagna hanno scoperto che...   \n38933 2020-04-08 17:22:29  Coronavirus, collaborazione medico scientifica...   \n32293 2020-03-31 11:48:11  RT @GDS_it: #Coronavirus, avvocato giustifica ...   \n3053  2020-03-08 23:21:58  \"bisogna farsi il segno della croce con l'acqu...   \n\n       favorite_count  retweet_count  ...  Geo Coordinates Checked_In_Place  \\\n14039             0.0            1.0  ...  NaN         NaN             None   \n25327             0.0          480.0  ...  NaN         NaN             None   \n38933             0.0            0.0  ...  NaN         NaN             None   \n32293             0.0            3.0  ...  NaN         NaN             None   \n3053              1.0            0.0  ...  NaN         NaN             None   \n\n          User_Location                RT_id  RT_Geo RT_Coordinates RT_Place  \\\n14039               NaN  1239475844218860032     NaN            NaN      NaN   \n25327       Roma, Lazio  1242368129273139968     NaN            NaN      NaN   \n38933           Palermo                 None    None           None     None   \n32293           marsala  1244937986065789952     NaN            NaN      NaN   \n3053   Palermo, Sicilia                 None    None           None     None   \n\n      RT_User_Location                               translated_full_text  \n14039          Palermo  RT @GDS_en: #Coronavirus, #Diodato on tv dedic...  \n25327          Palermo  RT @e_terranova: In #Spain they discovered tha...  \n38933             None  Coronavirus, scientific medical collaboration ...  \n32293          Palermo  RT @GDS_en: #Coronavirus, lawyer justifies sup...  \n3053              None  \"you have to make the sign of the cross with h...  \n\n[5 rows x 29 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>SearchKeywords</th>\n      <th>SearchCity</th>\n      <th>Time_Zone</th>\n      <th>tweet_ID</th>\n      <th>created_at</th>\n      <th>created_at_local</th>\n      <th>full_text</th>\n      <th>favorite_count</th>\n      <th>retweet_count</th>\n      <th>...</th>\n      <th>Geo</th>\n      <th>Coordinates</th>\n      <th>Checked_In_Place</th>\n      <th>User_Location</th>\n      <th>RT_id</th>\n      <th>RT_Geo</th>\n      <th>RT_Coordinates</th>\n      <th>RT_Place</th>\n      <th>RT_User_Location</th>\n      <th>translated_full_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>14039</th>\n      <td>14039</td>\n      <td>racism OR COVID-19 OR COVID2019 OR Lombardy OR...</td>\n      <td>Palermo</td>\n      <td>1.0</td>\n      <td>1.239500e+18</td>\n      <td>2020-03-16 10:31:28</td>\n      <td>2020-03-16 11:31:28</td>\n      <td>RT @GDS_it: #Coronavirus, #Diodato in tv dedic...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>1239475844218860032</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Palermo</td>\n      <td>RT @GDS_en: #Coronavirus, #Diodato on tv dedic...</td>\n    </tr>\n    <tr>\n      <th>25327</th>\n      <td>25327</td>\n      <td>racism OR COVID-19 OR COVID2019 OR Lombardy OR...</td>\n      <td>Palermo</td>\n      <td>1.0</td>\n      <td>1.242368e+18</td>\n      <td>2020-03-24 08:31:06</td>\n      <td>2020-03-24 09:31:06</td>\n      <td>RT @e_terranova: In #Spagna hanno scoperto che...</td>\n      <td>0.0</td>\n      <td>480.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>Roma, Lazio</td>\n      <td>1242368129273139968</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Palermo</td>\n      <td>RT @e_terranova: In #Spain they discovered tha...</td>\n    </tr>\n    <tr>\n      <th>38933</th>\n      <td>38933</td>\n      <td>racism OR COVID-19 OR COVID2019 OR Lombardy OR...</td>\n      <td>Palermo</td>\n      <td>1.0</td>\n      <td>1.247923e+18</td>\n      <td>2020-04-08 16:22:29</td>\n      <td>2020-04-08 17:22:29</td>\n      <td>Coronavirus, collaborazione medico scientifica...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>Palermo</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>Coronavirus, scientific medical collaboration ...</td>\n    </tr>\n    <tr>\n      <th>32293</th>\n      <td>32293</td>\n      <td>racism OR COVID-19 OR COVID2019 OR Lombardy OR...</td>\n      <td>Palermo</td>\n      <td>1.0</td>\n      <td>1.244940e+18</td>\n      <td>2020-03-31 10:48:11</td>\n      <td>2020-03-31 11:48:11</td>\n      <td>RT @GDS_it: #Coronavirus, avvocato giustifica ...</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>marsala</td>\n      <td>1244937986065789952</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Palermo</td>\n      <td>RT @GDS_en: #Coronavirus, lawyer justifies sup...</td>\n    </tr>\n    <tr>\n      <th>3053</th>\n      <td>3053</td>\n      <td>racism OR COVID-19 OR COVID2019 OR Lombardy OR...</td>\n      <td>Palermo</td>\n      <td>1.0</td>\n      <td>1.236779e+18</td>\n      <td>2020-03-08 22:21:58</td>\n      <td>2020-03-08 23:21:58</td>\n      <td>\"bisogna farsi il segno della croce con l'acqu...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>Palermo, Sicilia</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>\"you have to make the sign of the cross with h...</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 29 columns</p>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "# Read in data here\n",
    "location_name = \"Palermo\"\n",
    "text_data = pd.read_excel(f'C:\\\\Users\\\\jackm\\\\Documents\\\\COVID-CrowdFight\\\\data\\\\200514 - Jack\\\\Translated-{location_name}.xlsx')\n",
    "display(text_data.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
    }
   ],
   "source": [
    "# Import english stop words\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stopcorpus: typing.List = stopwords.words('english')\n",
    "print(stopcorpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "0    Coronavirus: Sonia, famous Chinese restaurant ...\n1    @sarregoeswest @SpudFNVPN \"More 73,300 infecte...\n2    The Unknown Unknowns risk Coronavirus? Competi...\n3    Coronavirus emergency. The mayor Modica taking...\n4    @sarregoeswest @SpudFNVPN But know Shanghai re...\nName: cleaned_text, dtype: object"
     },
     "metadata": {}
    }
   ],
   "source": [
    "# Convert to lowercase, and remove stop words\n",
    "\n",
    "def remove_links(text):\n",
    "    import re\n",
    "    return re.sub(r\"http\\S+\", \"\", text)\n",
    "\n",
    "text_data['translated_full_text'] = text_data['translated_full_text'].astype(str).apply(remove_links)\n",
    "\n",
    "def style_text(text:str):\n",
    "    return text.lower()\n",
    "\n",
    "def remove_words(text_data:str,list_of_words_to_remove: typing.List):\n",
    "    return [item for item in text_data if item not in list_of_words_to_remove]\n",
    "\n",
    "text_data['cleaned_text'] = text_data['translated_full_text'].astype(str).apply(style_text)\n",
    "\n",
    "text_data['cleaned_text'] = text_data['translated_full_text'].astype(str).apply(lambda x: remove_words(x.split(),stopcorpus))\n",
    "\n",
    "def collapse_list_to_string(string_list):\n",
    "    return ' '.join(string_list)\n",
    "\n",
    "text_data['cleaned_text'] = text_data['cleaned_text'].apply(collapse_list_to_string)\n",
    "\n",
    "display(text_data['cleaned_text'].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "0    Coronavirus: Sonia, famous Chinese restaurant ...\n1    @sarregoeswest @SpudFNVPN \"More 73,300 infecte...\n2    The Unknown Unknowns risk Coronavirus? Competi...\n3    Coronavirus emergency. The mayor Modica taking...\n4    @sarregoeswest @SpudFNVPN But know Shanghai re...\nName: clean_lemmatized, dtype: object"
     },
     "metadata": {}
    }
   ],
   "source": [
    "# Lemmatize cleaned text (stem words)\n",
    "\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]\n",
    "\n",
    "text_data['clean_lemmatized'] = text_data['cleaned_text'].astype(str).apply(lemmatize_text)\n",
    "\n",
    "text_data['clean_lemmatized'] = text_data['clean_lemmatized'].apply(collapse_list_to_string)\n",
    "\n",
    "display(text_data['clean_lemmatized'].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "                                           full_text  \\\n0  Coronavirus: chiude Sonia, il ristorante cines...   \n1  @sarregoeswest @SpudFNVPN https://t.co/DQorjEs...   \n2  I Soliti Ignoti a rischio per il Coronavirus? ...   \n3  Emergenza Coronavirus. Il sindaco di Modica ad...   \n4  @sarregoeswest @SpudFNVPN Ma che ne sai tu sei...   \n\n                                    clean_lemmatized  \\\n0  Coronavirus: Sonia, famous Chinese restaurant ...   \n1  @sarregoeswest @SpudFNVPN \"More 73,300 infecte...   \n2  The Unknown Unknowns risk Coronavirus? Competi...   \n3  Coronavirus emergency. The mayor Modica taking...   \n4  @sarregoeswest @SpudFNVPN But know Shanghai re...   \n\n                                translated_full_text  \n0  Coronavirus: Sonia, the famous Chinese restaur...  \n1  @sarregoeswest @SpudFNVPN  \"More than 73,300 i...  \n2  The Unknown Unknowns at risk for the Coronavir...  \n3  Coronavirus emergency. The mayor of Modica is ...  \n4  @sarregoeswest @SpudFNVPN But what do you know...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>full_text</th>\n      <th>clean_lemmatized</th>\n      <th>translated_full_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Coronavirus: chiude Sonia, il ristorante cines...</td>\n      <td>Coronavirus: Sonia, famous Chinese restaurant ...</td>\n      <td>Coronavirus: Sonia, the famous Chinese restaur...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>@sarregoeswest @SpudFNVPN https://t.co/DQorjEs...</td>\n      <td>@sarregoeswest @SpudFNVPN \"More 73,300 infecte...</td>\n      <td>@sarregoeswest @SpudFNVPN  \"More than 73,300 i...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I Soliti Ignoti a rischio per il Coronavirus? ...</td>\n      <td>The Unknown Unknowns risk Coronavirus? Competi...</td>\n      <td>The Unknown Unknowns at risk for the Coronavir...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Emergenza Coronavirus. Il sindaco di Modica ad...</td>\n      <td>Coronavirus emergency. The mayor Modica taking...</td>\n      <td>Coronavirus emergency. The mayor of Modica is ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>@sarregoeswest @SpudFNVPN Ma che ne sai tu sei...</td>\n      <td>@sarregoeswest @SpudFNVPN But know Shanghai re...</td>\n      <td>@sarregoeswest @SpudFNVPN But what do you know...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "output_df = pd.DataFrame(text_data[['full_text','clean_lemmatized','translated_full_text']].drop_duplicates())\n",
    "display(output_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "sid_analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(text:str, analyser,desired_type:str='pos'):\n",
    "    # Get sentiment from text\n",
    "    sentiment_score = analyser.polarity_scores(text)\n",
    "    return sentiment_score[desired_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Sentiment scores\n",
    "def get_sentiment_scores(df,data_column):\n",
    "    df[f'{data_column} Positive Sentiment Score'] = df[data_column].astype(str).apply(lambda x: get_sentiment(x,sid_analyzer,'pos'))\n",
    "    df[f'{data_column} Negative Sentiment Score'] = df[data_column].astype(str).apply(lambda x: get_sentiment(x,sid_analyzer,'neg'))\n",
    "    df[f'{data_column} Neutral Sentiment Score'] = df[data_column].astype(str).apply(lambda x: get_sentiment(x,sid_analyzer,'neu'))\n",
    "    df[f'{data_column} Compound Sentiment Score'] = df[data_column].astype(str).apply(lambda x: get_sentiment(x,sid_analyzer,'compound'))\n",
    "    return df\n",
    "\n",
    "output_df = get_sentiment_scores(output_df,'translated_full_text')\n",
    "output_df = get_sentiment_scores(output_df,'clean_lemmatized')\n",
    "display(output_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.to_excel(f'{location_name}-Sentiment-Analysis.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.plot.hist(subplots=True,grid=True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{location_name}-sentiment-histograms.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "exclude_words = [\"http\",\"https\",\"error\"]\n",
    "\n",
    "exclude_words.extend(stopcorpus)\n",
    "\n",
    "output_df['wordcloud'] = output_df['translated_full_text'].astype(str).apply(remove_links)\n",
    "\n",
    "output_df['wordcloud'] = output_df['wordcloud'].astype(str).apply(lambda x: x.lower())\n",
    "\n",
    "def remove_apostrophes(text):\n",
    "    text = text.replace(\"'\", \"\")\n",
    "    text = text.replace('\"', \"\")\n",
    "    return text\n",
    "\n",
    "output_df['wordcloud'] = output_df['wordcloud'].astype(str).apply(remove_apostrophes)\n",
    "\n",
    "output_df['wordcloud'] = output_df['wordcloud'].astype(str).apply(lambda x: remove_words(x.split(),exclude_words))\n",
    "\n",
    "output_df['wordcloud'] = output_df['wordcloud'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "display(output_df['wordcloud'])\n",
    "\n",
    "wordcloud = WordCloud().generate(' '.join(output_df['wordcloud'].astype(str)))\n",
    "\n",
    "wordcloud.to_file(f\"{location_name}-wordcloud.png\")\n",
    "\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38164bitenvvenvc025e48d0ba841a68c41703c78d5e202",
   "display_name": "Python 3.8.1 64-bit ('.env': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}